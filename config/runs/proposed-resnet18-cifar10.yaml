run_id: proposed-resnet18-cifar10
method: Dynamic Soft Augmentation with Dual Consistency
model:
  name: resnet18
  num_parameters: 11000000
  backbone: ResNet-18
  pretrained: false
dataset:
  name: cifar10
  image_size: 32
  channels: 3
  train_split: 45000
  val_split: 5000
  test_split: 10000
  preprocessing:
    augmentation: randaugment
    normalize: true
training:
  learning_rate: 0.1
  batch_size: 128
  epochs: 100
  optimizer: sgd
  momentum: 0.9
  warmup_steps: 500
  weight_decay: 0.0001
  gradient_clip: 1.0
  scheduler: linear
  seed: 42
  additional_params:
    modulation_network_layers: [16, 2]
    feature_projector_output_dim: 64
    soft_target_params:
      pmin: 0.5
      k: 2
optuna:
  n_trials: 20
  search_spaces:
    - param_name: learning_rate
      distribution_type: loguniform
      low: 0.0001
      high: 0.1
    - param_name: weight_decay
      distribution_type: loguniform
      low: 1e-05
      high: 0.01
    - param_name: dynamic_weight_scale
      distribution_type: uniform
      low: 0.5
      high: 2.0